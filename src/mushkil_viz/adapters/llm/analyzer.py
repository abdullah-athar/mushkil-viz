import json
import logging
from typing import Any, Dict, List, Optional

import numpy as np
import pandas as pd
from pydantic import BaseModel, Field
from scipy import stats

from mushkil_viz.core.analyzers.base import BaseAnalyzer
from mushkil_viz.core.client_init import init_openai_client

logger = logging.getLogger(__name__)
logging.basicConfig(
    level=logging.DEBUG,
    format="%(asctime)s [%(levelname)s] %(name)s - %(message)s"
)



class AnalysisFunction(BaseModel):
    """Schema for an analysis function generated by the LLM."""
    name: str = Field(..., description="Name of the analysis function")
    description: str = Field(..., description="Detailed description of what the function does")
    parameters: Dict[str, Any] = Field(..., description="Parameters required by the function")
    returns: Dict[str, Any] = Field(..., description="Return type and description")
    code: str = Field(..., description="The actual Python code for the function")

    def get_signature(self) -> str:
        """Returns a readable function signature"""
        params = ", ".join([f"{k}: {v['type']}" for k, v in self.parameters.items()])
        return f"{self.name}({params}) -> {self.returns['type']}"

    def __str__(self) -> str:
        """Returns a readable string representation"""
        return f"Function: {self.get_signature()}\nDescription: {self.description}\n"


class AnalysisResult(BaseModel):
    """Schema for the result of an analysis function."""
    name: str = Field(..., description="Name of the analysis that was performed")
    description: str = Field(..., description="Description of the analysis")
    result: Dict[str, Any] = Field(..., description="The results of the analysis")
    visualization_hints: Optional[Dict[str, str]] = Field(
        None, description="Hints for how to visualize this result"
    )


class DatasetContext(BaseModel):
    column_types: Dict[str, List[str]] = Field(..., description="Mapping of column types to column names")
    sample_data: Dict[str, List[Any]] = Field(..., description="Sample values from each column")
    basic_stats: Dict[str, Dict[str, float]] = Field(..., description="Basic statistical measures for numeric columns")
    column_descriptions: Dict[str, str] = Field(..., description="Description of what each column represents")


class AnalysisPlan(BaseModel):
    """Schema for the complete analysis plan from the LLM."""
    functions: List[AnalysisFunction] = Field(..., description="List of analysis functions to execute")


class LLMAnalyzer(BaseAnalyzer):
    """Analyzer that uses LLMs to generate and execute data analysis functions."""
    
    def __init__(self, api_key: Optional[str] = None, api_base: Optional[str] = None):
        super().__init__()
        self.client = init_openai_client(api_key, api_base)
        self.model = "google/gemini-2.0-flash-lite-preview-02-05:free"
        
        # Create function schema using Pydantic model
        self.function_schema = {
    "type": "function",
    "function": {
        "name": "provide_analysis_plan",
        "description": "Generate analysis functions based on the dataset context",
        "parameters": {
            "type": "object",
            "properties": {
                "functions": {
                    "type": "array",
                    "items": {
                        "type": "object",
                        "properties": {
                            "name": {
                                "type": "string",
                                "description": "Name of the analysis function"
                            },
                            "description": {
                                "type": "string",
                                "description": "Description of what the function does"
                            },
                            "parameters": {
                                "type": "object",
                                "description": "Parameters required by the function",
                                "additionalProperties": {
                                    "type": "object",
                                    "properties": {
                                        "type": {
                                            "type": "string",
                                            "description": "Parameter type"
                                        },
                                        "description": {
                                            "type": "string",
                                            "description": "Parameter description"
                                        }
                                    },
                                    "required": ["type", "description"]
                                }
                            },
                            "returns": {
                                "type": "object",
                                "properties": {
                                    "type": {
                                        "type": "string",
                                        "description": "Return type"
                                    },
                                    "description": {
                                        "type": "string",
                                        "description": "Description of the return value"
                                    }
                                },
                                "required": ["type", "description"]
                            },
                            "code": {
                                "type": "string",
                                "description": "The actual Python code for the function"
                            }
                        },
                        "required": ["name", "description", "parameters", "returns", "code"]
                    }
                }
            },
            "required": ["functions"]
        }
    }
}

        
        self.system_prompt = (
            "You are a data analysis expert. Your task is to generate Python functions that perform meaningful "
            "analyses on the dataset.\n"
            "For each analysis function:\n"
            "1. Give it a descriptive name\n"
            "2. Provide a clear description of what it analyzes\n"
            "3. Write efficient Pandas/NumPy code to perform the analysis\n"
            "4. List the required columns\n"
            "5. Include appropriate error handling\n"
            "6. Return results in a format suitable for visualization\n\n"
            "Focus on:\n"
            "- Statistical relationships between variables\n"
            "- Distributions and patterns\n"
            "- Aggregations and groupings\n"
            "- Temporal patterns (if time-based data exists)\n"
            "- Geographical patterns (if location data exists)\n"
            "- Key business/domain metrics\n\n"
            "The code should be production-ready and handle edge cases (nulls, outliers, etc.)."
        )

        logger.debug("LLMAnalyzer initialized with model: %s", self.model)

    def _generate_analysis_functions(self, context: DatasetContext) -> List[AnalysisFunction]:
        """Generate analysis functions based on the dataset context."""
        logger.debug("Generating analysis functions with context: %s", context.model_dump())
        
        user_prompt = (
            f"Dataset Context:\n"
            f"Column Types: {json.dumps(context.column_types, indent=2)}\n"
            f"Sample Data: {json.dumps(context.sample_data, indent=2)}\n"
            f"Basic Stats: {json.dumps(context.basic_stats, indent=2)}\n"
            f"Column Descriptions: {json.dumps(context.column_descriptions, indent=2)}\n\n"
            "Please generate appropriate analysis functions for this dataset."
        )

        logger.debug("Sending prompt to LLM with length: %d", len(user_prompt))

        response = self.client.chat.completions.create(
            model=self.model,
            messages=[
                {"role": "system", "content": self.system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            tools=[self.function_schema],
            tool_choice={"type": "function", "function": {"name": "provide_analysis_plan"}}
        )
        logger.debug("Response: %s", response.choices[0])
        
        function_call = response.choices[0].message.tool_calls
        logger.debug("Received function call: %s", function_call)
        
        # Parse the JSON arguments from the function call into an AnalysisPlan
        function_call_data = json.loads(function_call[0].function.arguments)
        logger.debug("Received analysis plan with %d functions", len(function_call_data["functions"]))
        return [AnalysisFunction.model_validate(func) for func in function_call_data["functions"]]

    def _execute_analysis_function(self, df: pd.DataFrame, analysis: AnalysisFunction) -> AnalysisResult:
        """Execute a single analysis function and return its results."""
        logger.debug("Executing analysis function: %s", analysis.name)
        try:
            # Create the function namespace with necessary imports
            namespace = {
                'pd': pd,
                'np': np,
                'stats': stats,
                'df': df
            }
            
            exec(analysis.code, namespace)
            func = namespace.get(analysis.name, None)
            if not func:
                raise ValueError(f"Function {analysis.name} not found in the executed code.")

            # Get the result from the namespace (expected to be set by the executed code)
            result = func(df, **analysis.parameters)
            if result is None:
                raise ValueError("Analysis function did not produce a 'result' variable")
            
            logger.debug("Successfully executed analysis: %s", analysis.name)
            return AnalysisResult(
                name=analysis.name,
                description=analysis.description,
                result=result if isinstance(result, dict) else result.to_dict(),
                visualization_hints=namespace.get('visualization_hints', None)
            )
        except Exception as e:
            logger.error("Error executing analysis %s: %s", analysis.name, str(e))
            return AnalysisResult(
                name=analysis.name,
                description=analysis.description,
                result={'error': str(e)},
                visualization_hints=None
            )

    def analyze(self, df: pd.DataFrame) -> Dict:
        """Perform comprehensive analysis of the dataset using LLM-generated functions."""
        logger.debug("Starting analysis on DataFrame with shape: %s", str(df.shape))
        
        # First, run the parent class analysis
        base_analysis = super().analyze(df)
        logger.debug("Completed base analysis")
        
        # Prepare enhanced context for LLM
        context = DatasetContext(
            column_types=base_analysis["dataset_info"]["column_types"],
            sample_data={col: df[col].head(5).tolist() for col in df.columns},
            basic_stats=base_analysis["basic_stats"],
            column_descriptions={col: f"Column containing {col.replace('_', ' ')}" for col in df.columns}
        )
        
        # Generate analysis functions from the LLM
        analysis_functions = self._generate_analysis_functions(context)
        logger.debug("Generated %d analysis functions", len(analysis_functions))
        
        # Execute each analysis function and collect results
        analysis_results = []
        for func in analysis_functions:
            # Check if required columns are available (based on parameter type)
            required_columns = [
                param for param, details in func.parameters.items() 
                if details.get('type', '').startswith('pd.Series')
            ]
            
            missing_columns = [col for col in required_columns if col not in df.columns]
            if not missing_columns:
                logger.debug("Running analysis function: %s (requires columns: %s)", func.name, required_columns)
                result = self._execute_analysis_function(df, func)
                analysis_results.append(result.model_dump())
            else:
                logger.warning(
                    "Skipping analysis %s: missing required columns %s", 
                    func.name, missing_columns
                )
        
        logger.debug("Completed %d analyses", len(analysis_results))
        
        # Combine base analysis with function results
        results = base_analysis
        results["analysis_results"] = analysis_results
        
        return results 
    

if __name__ == "__main__":
    analyzer = LLMAnalyzer()
    df = pd.read_csv("examples/financial_data.csv")
    results = analyzer.analyze(df)
    
    
    
    # Optionally, print details for each generated analysis function
    for analysis in results.get("analysis_results", []):
        print(f"Function Name: {analysis['name']}")
        print(f"Description: {analysis['description']}")
        print("Result:")
        print(analysis['result'])
        print("-" * 50)

    breakpoint()
